# IA COURS 4 - Projet

## Technologies utilis√©es
* Version Python : 3.11 üêç
* Formatter : Black ‚ö´
* Linter : Pylint üßπ
* Static type checker : Pyright üîç
* Outils de gestion de d√©pendances : Poetry üì¶
* Outils de gestion des pre-commit hooks : Pre-commit üé£

## Description
Ce projet a pour objectif d'entrainer un mod√®le d'IA en Python capable de d√©tecter des produits comme des mikado, des kinder pinguin, des bouteilles en plastique, etc..., sur des images, des vid√©os ou via une cam√©ra.

Le projet comprend deux pipelines :
* **Pipeline de training** : utilisation d‚Äôun dataset annot√© sur [Picsellia](https://www.picsellia.com/) pour entra√Æner un mod√®le de d√©tection d'objets avec les mod√®les YOLO d'[Ultralytics](https://www.ultralytics.com/fr).
* **Pipeline d'inf√©rence** : charge le mod√®le entra√Æn√© pour effectuer des d√©tections sur des images, vid√©os ou via une webcam.

Picsellia est utilis√© pour l'annotation des datasets et le suivi des exp√©rimentationss.
Ultralytics et ses mod√®les YOLO sont choisis pour la d√©tection d'objets.

## Difficult√©s et exp√©rimentations

- **Nombre d'epochs** : d√©passer les **400-500 epochs** ne semble pas am√©liorer les performances du mod√®le. Apr√®s ce seuil, l'apprentissage stagne, et les r√©sultats ne changent plus vraiment, peu importe les hyperparam√®tres.
- **Hyperparam√®tres** : ajuster les hyperparam√®tres n‚Äôest pas facile. Il est difficile de savoir quels param√®tres modifier pour am√©liorer les performances. Le **fine-tuning** pourrait √™tre une solution, mais avec nos GPU, cela prend beaucoup trop de temps.
- **Probl√®mes avec CUDA et l'utilisation du GPU**
- **Coordonn√©es des pr√©dictions** : lorsque l'on log les images de test dans l'onglet **√âvaluation** de Picsellia, les coordonn√©es retourn√©es par Ultralytics sont en **centered-centered**, tandis que Picsellia attend un format **top-left**. Cela nous a pris un moment avant de comprendre d'o√π venait le probl√®me.
- **Crashs pendant l'entra√Ænement** : quand l'entra√Ænement plante en cours de route :üòë.
- **Param√®tres ajust√©s** : nous avons principalement jou√© avec **epochs**, **patience**, **learning rate**, **batch size** et **img size**.
  - Augmenter le **batch size** rend l'entra√Ænement beaucoup plus long, avec peu de gains en pr√©cision.
- **Mod√®le** : globalement, le mod√®le est plut√¥t correct, mais il rencontre plusieurs difficult√©s :
  - Il confond souvent le **background** avec des objets.
  - Il n'arrive pas toujours √† d√©tecter des objets l√† o√π ils se trouvent Ô∏è.
  - Il a aussi du mal avec les diff√©rentes variantes de **Kinder**.
- **Versions de mod√®le** : nous avons test√© diff√©rentes versions de YOLO (nano, small, xl...), mais l'entra√Ænement peut alors devenir tr√®s long.
- **SDK Picsellia et Ultralytics** : certains snippets de Picsellia ne fonctionnent pas, ce qui nous a fait perdre pas mal de temps.


## Pistes d'am√©lioration

- L'utilisation d'un dataset plus cons√©quent pourrait am√©liorer les performances des mod√®les entrain√©s
- **Fine-tuning :** comme mentionn√© pr√©c√©demment, le fine-tuning pourrait am√©liorer les r√©sultats. Cependant, il serait n√©cessaire de le tester sur des machines plus performantes.

## Meilleur mod√®le
Disponible [ici](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936420-552b-796d-a41c-3b3bf1f7348f/experiment/0194df46-9bc6-75ce-87e5-6f4f6f63beb9/)

Version du mod√®le YOLO utilis√© : yolov11l

Hyperparam√®tres :
```python
lr0: 0.005
seed: 42
batch: 32
cache: true
imgsz: 640
mixup: true
epochs: 300
mosaic: true
augment: true
momentum: 0.9
patience: 50
optimizer: AdamW
close_mosaic: 0
weight_decay: 0.0004
label_smoothing: 0.05
```

Matrice de confusion :

![img.png](img.png)

## Installation
```shell
git clone https://github.com/joe67100/ia-cours-4.git
cd ia-cours-4
poetry install

# Si poetry n'est pas install√© :
# pip install poetry
```

## Utilisation

Pour lancer une session d'entra√Ænement, utilisez la commande suivante:
```shell
python main.py train [-h] --dataset_version DATASET_VERSION --project_name PROJECT_NAME
```
Example:
```shell
python main.py train --dataset_version initial --project_name Groupe_2
```
---

Pour lancer une session d'inf√©rence, utilisez la commande suivante:
```shell
python main.py infer [-h] --model MODEL --model_version MODEL_VERSION {video,image,camera}
```
Examples:
```shell
# For video
python main.py infer --model Groupe_2 --model_version Groupe_2-55 video "C:\videoplayback.mp4"
```
```shell
# For image
python main.py infer --model Groupe_2 --model_version Groupe_2-55 image "C:\image.jpg"
```
```shell
# For camera
python main.py infer --model Groupe_2 --model_version Groupe_2-55 camera
```

## Liens utiles
- [Picsellia : Projects / Groupe_2](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936420-552b-796d-a41c-3b3bf1f7348f)
- [**Meilleur model_version**](https://app.picsellia.com/0192f6db-86b6-784c-80e6-163debb242d5/project/01936420-552b-796d-a41c-3b3bf1f7348f/experiment/0194df46-9bc6-75ce-87e5-6f4f6f63beb9/)


## Auteurs

<table style="width:100%; text-align:center;">
  <tr>
    <td><a href="https://github.com/joe67100"><img src="https://avatars.githubusercontent.com/u/71235356?v=4?s=100" alt="Joe67100's profile picture" /></a></td>
    <td><a href="https://github.com/Bricklou"><img src="https://avatars.githubusercontent.com/u/15181236?v=4?s=100" alt="Bilou's profile picture" /></a></td>
    <td><a href="https://github.com/AIsamet"><img src="https://avatars.githubusercontent.com/u/94604758?v=4?s=100" alt="Isamet's profile picture" /></a></td>
  </tr>
  <tr>
    <td><a href="https://github.com/joe67100">Jo√©</a>
    <td><a href="https://github.com/Bricklou">Bilou</a>
    <td><a href="https://github.com/AIsamet">Isamet</a>
  </tr>
</table>
